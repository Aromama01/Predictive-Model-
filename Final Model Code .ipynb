{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:19.856171Z",
     "start_time": "2024-01-14T12:09:19.780982200Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 699 rows and 48 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = 'DEMO_Dataset.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "num_rows, num_columns = df.shape\n",
    "print(f'The dataset has {num_rows} rows and {num_columns} columns.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3705daa902db8dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:20.400549500Z",
     "start_time": "2024-01-14T12:09:20.353020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR                     0\n",
       "TARGET                         0\n",
       "NAME_CONTRACT_TYPE             0\n",
       "CODE_GENDER                    0\n",
       "CNT_CHILDREN                   0\n",
       "AMT_INCOME_TOTAL               0\n",
       "AMT_ANNUITY                    0\n",
       "NAME_TYPE_SUITE                0\n",
       "NAME_INCOME_TYPE               0\n",
       "NAME_EDUCATION_TYPE            0\n",
       "NAME_FAMILY_STATUS             0\n",
       "NAME_HOUSING_TYPE              0\n",
       "REGION_POPULATION_RELATIVE     0\n",
       "DAYS_BIRTH                     0\n",
       "DAYS_EMPLOYED                  0\n",
       "DAYS_REGISTRATION              0\n",
       "DAYS_ID_PUBLISH                0\n",
       "OCCUPATION_TYPE                0\n",
       "CNT_FAM_MEMBERS                0\n",
       "REGION_RATING_CLIENT           0\n",
       "REGION_RATING_CLIENT_W_CITY    0\n",
       "WEEKDAY_APPR_PROCESS_START     0\n",
       "HOUR_APPR_PROCESS_START        0\n",
       "REG_REGION_NOT_LIVE_REGION     0\n",
       "REG_REGION_NOT_WORK_REGION     0\n",
       "LIVE_REGION_NOT_WORK_REGION    0\n",
       "REG_CITY_NOT_LIVE_CITY         0\n",
       "REG_CITY_NOT_WORK_CITY         0\n",
       "LIVE_CITY_NOT_WORK_CITY        0\n",
       "ORGANIZATION_TYPE              0\n",
       "EXT_SOURCE_2                   0\n",
       "EXT_SOURCE_3                   0\n",
       "OBS_30_CNT_SOCIAL_CIRCLE       0\n",
       "DEF_30_CNT_SOCIAL_CIRCLE       0\n",
       "OBS_60_CNT_SOCIAL_CIRCLE       0\n",
       "DEF_60_CNT_SOCIAL_CIRCLE       0\n",
       "DAYS_LAST_PHONE_CHANGE         0\n",
       "AMT_REQ_CREDIT_BUREAU_HOUR     0\n",
       "AMT_REQ_CREDIT_BUREAU_DAY      0\n",
       "AMT_REQ_CREDIT_BUREAU_WEEK     0\n",
       "AMT_REQ_CREDIT_BUREAU_MON      0\n",
       "AMT_REQ_CREDIT_BUREAU_QRT      0\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR     0\n",
       "SK_ID_PREV                     0\n",
       "AMT_APPLICATION                0\n",
       "CNT_PAYMENT                    0\n",
       "AMT_CREDIT                     0\n",
       "AMT_GOODS_PRICE                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3453a269f639a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:20.886918100Z",
     "start_time": "2024-01-14T12:09:20.847539300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SK_ID_CURR  TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_ANNUITY  \\\n",
      "0      100002       1             0            202500      24700.5   \n",
      "1      100003       0             0            270000      35698.5   \n",
      "2      100003       0             0            270000      35698.5   \n",
      "3      100004       0             0             67500       6750.0   \n",
      "4      100006       0             0            135000      29686.5   \n",
      "\n",
      "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
      "0                    0.018801       -9461           -637              -3648   \n",
      "1                    0.003541      -16765          -1188              -1186   \n",
      "2                    0.003541      -16765          -1188              -1186   \n",
      "3                    0.010032      -19046           -225              -4260   \n",
      "4                    0.008019      -19005          -3039              -9833   \n",
      "\n",
      "   DAYS_ID_PUBLISH  ... ORGANIZATION_TYPE_Self-employed  \\\n",
      "0            -2120  ...                           False   \n",
      "1             -291  ...                           False   \n",
      "2             -291  ...                           False   \n",
      "3            -2531  ...                           False   \n",
      "4            -2437  ...                           False   \n",
      "\n",
      "   ORGANIZATION_TYPE_Services  ORGANIZATION_TYPE_Trade: type 2  \\\n",
      "0                       False                            False   \n",
      "1                       False                            False   \n",
      "2                       False                            False   \n",
      "3                       False                            False   \n",
      "4                       False                            False   \n",
      "\n",
      "   ORGANIZATION_TYPE_Trade: type 3  ORGANIZATION_TYPE_Trade: type 7  \\\n",
      "0                            False                            False   \n",
      "1                            False                            False   \n",
      "2                            False                            False   \n",
      "3                            False                            False   \n",
      "4                            False                            False   \n",
      "\n",
      "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
      "0                                False                                False   \n",
      "1                                False                                False   \n",
      "2                                False                                False   \n",
      "3                                False                                False   \n",
      "4                                False                                False   \n",
      "\n",
      "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
      "0                                False                         False   \n",
      "1                                False                         False   \n",
      "2                                False                         False   \n",
      "3                                False                         False   \n",
      "4                                False                         False   \n",
      "\n",
      "   ORGANIZATION_TYPE_XNA  \n",
      "0                  False  \n",
      "1                  False  \n",
      "2                  False  \n",
      "3                  False  \n",
      "4                  False  \n",
      "\n",
      "[5 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select categorical columns for one-hot encoding\n",
    "categorical_columns = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE']\n",
    "\n",
    "# Apply one-hot encoding to the selected columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af6fc15073a3030f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:21.500103700Z",
     "start_time": "2024-01-14T12:09:21.452989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_ANNUITY  REGION_POPULATION_RELATIVE  \\\n",
      "0     -0.607043          0.286860    -0.281596                   -0.201373   \n",
      "1     -0.607043          1.076808     0.508195                   -1.170712   \n",
      "2     -0.607043          1.076808     0.508195                   -1.170712   \n",
      "3     -0.607043         -1.293036    -1.570661                   -0.758393   \n",
      "4     -0.607043         -0.503088     0.076460                   -0.886262   \n",
      "\n",
      "   DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  \\\n",
      "0    1.660585      -0.400471           0.350635         0.495393   \n",
      "1   -0.151526      -0.404697           1.114909         1.707662   \n",
      "2   -0.151526      -0.404697           1.114909         1.707662   \n",
      "3   -0.717438      -0.397312           0.160652         0.222980   \n",
      "4   -0.707266      -0.418890          -1.569366         0.285284   \n",
      "\n",
      "   CNT_FAM_MEMBERS  REGION_RATING_CLIENT  ...  \\\n",
      "0        -1.218293             -0.048510  ...   \n",
      "1        -0.149803             -2.167782  ...   \n",
      "2        -0.149803             -2.167782  ...   \n",
      "3        -1.218293             -0.048510  ...   \n",
      "4        -0.149803             -0.048510  ...   \n",
      "\n",
      "   ORGANIZATION_TYPE_Self-employed  ORGANIZATION_TYPE_Services  \\\n",
      "0                            False                       False   \n",
      "1                            False                       False   \n",
      "2                            False                       False   \n",
      "3                            False                       False   \n",
      "4                            False                       False   \n",
      "\n",
      "   ORGANIZATION_TYPE_Trade: type 2  ORGANIZATION_TYPE_Trade: type 3  \\\n",
      "0                            False                            False   \n",
      "1                            False                            False   \n",
      "2                            False                            False   \n",
      "3                            False                            False   \n",
      "4                            False                            False   \n",
      "\n",
      "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 2  \\\n",
      "0                            False                                False   \n",
      "1                            False                                False   \n",
      "2                            False                                False   \n",
      "3                            False                                False   \n",
      "4                            False                                False   \n",
      "\n",
      "   ORGANIZATION_TYPE_Transport: type 3  ORGANIZATION_TYPE_Transport: type 4  \\\n",
      "0                                False                                False   \n",
      "1                                False                                False   \n",
      "2                                False                                False   \n",
      "3                                False                                False   \n",
      "4                                False                                False   \n",
      "\n",
      "   ORGANIZATION_TYPE_University  ORGANIZATION_TYPE_XNA  \n",
      "0                         False                  False  \n",
      "1                         False                  False  \n",
      "2                         False                  False  \n",
      "3                         False                  False  \n",
      "4                         False                  False  \n",
      "\n",
      "[5 rows x 139 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Select numerical columns for scaling\n",
    "numerical_columns = ['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_ANNUITY', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'AMT_APPLICATION', 'CNT_PAYMENT', 'AMT_CREDIT', 'AMT_GOODS_PRICE']\n",
    "\n",
    "# Separate the numerical columns from the DataFrame\n",
    "numerical_data = df[numerical_columns]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical data\n",
    "scaled_data = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# Create a DataFrame with the scaled numerical data\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=numerical_columns)\n",
    "\n",
    "# Concatenate the scaled numerical data with the one-hot encoded categorical data\n",
    "df_final = pd.concat([df_scaled, df_encoded], axis=1)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bc790f8db251578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:22.015106700Z",
     "start_time": "2024-01-14T12:09:21.989211500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_features = [ 'DAYS_BIRTH', 'AMT_CREDIT', 'ORGANIZATION_TYPE','DAYS_REGISTRATION','DAYS_ID_PUBLISH','OCCUPATION_TYPE','AMT_ANNUITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50a5a4988bdd03c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:22.479559400Z",
     "start_time": "2024-01-14T12:09:22.455530700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (559, 7), y_train shape: (559,)\n",
      "X_test shape: (140, 7), y_test shape: (140,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Select features (X) and target variable (y) based on the selected features\n",
    "selected_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'ORGANIZATION_TYPE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OCCUPATION_TYPE', 'AMT_ANNUITY']\n",
    "X = df[selected_features]\n",
    "y = df['TARGET']  # Assuming 'TARGET' is the column you want to predict\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "numerical_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'AMT_ANNUITY']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformers to different feature subsets\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and a Random Forest classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e7731378f905f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:23.577048500Z",
     "start_time": "2024-01-14T12:09:23.029401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "Mean Squared Error (MSE): 0.0000\n",
      "Mean Absolute Error (MAE): 0.0000\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      "[[138   0]\n",
      " [  0   2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       138\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       140\n",
      "   macro avg       1.00      1.00      1.00       140\n",
      "weighted avg       1.00      1.00      1.00       140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_model.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "# Additional metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(pipeline, 'random_forest_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f75d61ed76af3d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:23.782028700Z",
     "start_time": "2024-01-14T12:09:23.722353400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 99.29%\n",
      "Mean Squared Error (MSE): 0.0071\n",
      "Mean Absolute Error (MAE): 0.0071\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      "[[137   1]\n",
      " [  0   2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       138\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.99       140\n",
      "   macro avg       0.83      1.00      0.90       140\n",
      "weighted avg       1.00      0.99      0.99       140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, recall_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Select features (X) and target variable (y) based on the selected features\n",
    "selected_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'ORGANIZATION_TYPE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OCCUPATION_TYPE', 'AMT_ANNUITY']\n",
    "X = df[selected_features]\n",
    "y = df['TARGET']  # Assuming 'TARGET' is the column you want to predict\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "numerical_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'AMT_ANNUITY']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformers to different feature subsets\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and a Decision Tree classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "# Additional metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(pipeline, 'decision_tree_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b38e7d4abd6a5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:28.090535200Z",
     "start_time": "2024-01-14T12:09:25.430957100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 99.29%\n",
      "Mean Squared Error (MSE): 0.0071\n",
      "Mean Absolute Error (MAE): 0.0071\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      "[[137   1]\n",
      " [  0   2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       138\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.99       140\n",
      "   macro avg       0.83      1.00      0.90       140\n",
      "weighted avg       1.00      0.99      0.99       140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ann_model.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Select features (X) and target variable (y) based on the selected features\n",
    "selected_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'ORGANIZATION_TYPE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OCCUPATION_TYPE', 'AMT_ANNUITY']\n",
    "X = df[selected_features]\n",
    "y = df['TARGET'] \n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "numerical_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'AMT_ANNUITY']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformers to different feature subsets\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and an MLP (Multi-Layer Perceptron) classifier\n",
    "mlp_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', MLPClassifier(random_state=42, max_iter=500))])\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Additional metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(mlp_pipeline, 'ann_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90b25f8c1bb1465d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:28.093587100Z",
     "start_time": "2024-01-14T12:09:28.092082300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75738f4cfce799d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:29.375054300Z",
     "start_time": "2024-01-14T12:09:29.313357300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 73.57%\n",
      "Mean Squared Error (MSE): 0.2643\n",
      "Mean Absolute Error (MAE): 0.2643\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      "[[101  37]\n",
      " [  0   2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85       138\n",
      "           1       0.05      1.00      0.10         2\n",
      "\n",
      "    accuracy                           0.74       140\n",
      "   macro avg       0.53      0.87      0.47       140\n",
      "weighted avg       0.99      0.74      0.83       140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['naive_bayes_model.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, recall_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('to_dense', DenseTransformer()),  \n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "try:\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "except ValueError:\n",
    "    recall = float('nan')  \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(pipeline, 'naive_bayes_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e8b96cbaa89e5e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:31.896626400Z",
     "start_time": "2024-01-14T12:09:31.176003700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "Mean Squared Error (MSE): 0.0000\n",
      "Mean Absolute Error (MAE): 0.0000\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      "[[138   0]\n",
      " [  0   2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       138\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       140\n",
      "   macro avg       1.00      1.00      1.00       140\n",
      "weighted avg       1.00      1.00      1.00       140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gradient_boosting_model.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, recall_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' containing your dataset\n",
    "# If not, load your dataset before this point\n",
    "\n",
    "# Select features (X) and target variable (y) based on the selected features\n",
    "selected_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'ORGANIZATION_TYPE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OCCUPATION_TYPE', 'AMT_ANNUITY']\n",
    "X = df[selected_features]\n",
    "y = df['TARGET']  # Assuming 'TARGET' is the column you want to predict\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "numerical_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'AMT_ANNUITY']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformers to different feature subsets\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and a Gradient Boosting classifier\n",
    "gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Additional metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(gb_pipeline, 'gradient_boosting_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "757f16e366c9765a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:09:33.980436400Z",
     "start_time": "2024-01-14T12:09:33.916713400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 99.29%\n",
      "Mean Squared Error (MSE): 0.0071\n",
      "Mean Absolute Error (MAE): 0.0071\n",
      "Recall: 0.5000\n",
      "Confusion Matrix:\n",
      "[[138   0]\n",
      " [  1   1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       138\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       140\n",
      "   macro avg       1.00      0.75      0.83       140\n",
      "weighted avg       0.99      0.99      0.99       140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_model.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, recall_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Select features (X) and target variable (y) based on the selected features\n",
    "selected_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'ORGANIZATION_TYPE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OCCUPATION_TYPE', 'AMT_ANNUITY']\n",
    "X = df[selected_features]\n",
    "y = df['TARGET']  # Assuming 'TARGET' is the column you want to predict\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "numerical_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'AMT_ANNUITY']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformers to different feature subsets\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and an SVM classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', SVC(random_state=42))])\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Additional metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(pipeline, 'svm_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb33447e31210636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:17:02.405282900Z",
     "start_time": "2024-01-14T12:16:59.604999700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 100.00%\n",
      "Mean Squared Error (MSE) for Ensemble Model: 0.0000\n",
      "Mean Absolute Error (MAE) for Ensemble Model: 0.0000\n",
      "Recall for Ensemble Model: 1.0000\n",
      "Confusion Matrix for Ensemble Model:\n",
      "[[138   0]\n",
      " [  0   2]]\n",
      "Classification Report for Ensemble Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       138\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       140\n",
      "   macro avg       1.00      1.00      1.00       140\n",
      "weighted avg       1.00      1.00      1.00       140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ensemble_model_predictions.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, recall_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Select features (X) and target variable (y) based on the selected features\n",
    "selected_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'ORGANIZATION_TYPE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OCCUPATION_TYPE', 'AMT_ANNUITY']\n",
    "X = df[selected_features]\n",
    "y = df['TARGET']  # Assuming 'TARGET' is the column you want to predict\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']\n",
    "numerical_features = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'AMT_ANNUITY']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformers to different feature subsets\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "common_pipeline_steps = [('preprocessor', preprocessor)]\n",
    "\n",
    "# Assuming DenseTransformer and the code for it are defined elsewhere\n",
    "dense_pipeline_steps = common_pipeline_steps + [('to_dense', DenseTransformer())]\n",
    "\n",
    "# Create pipelines for each model (add DenseTransformer only if needed)\n",
    "rf_pipeline = Pipeline(common_pipeline_steps + [('classifier', RandomForestClassifier(random_state=42))])\n",
    "dt_pipeline = Pipeline(common_pipeline_steps + [('classifier', DecisionTreeClassifier(random_state=42))])\n",
    "svm_pipeline = Pipeline(dense_pipeline_steps + [('classifier', SVC(random_state=42))])\n",
    "nb_pipeline = Pipeline(dense_pipeline_steps + [('classifier', GaussianNB())])\n",
    "ann_pipeline = Pipeline(dense_pipeline_steps + [('classifier', MLPClassifier(random_state=42, max_iter=500))])\n",
    "gb_pipeline = Pipeline(common_pipeline_steps + [('classifier', GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit each model\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "ann_pipeline.fit(X_train, y_train)\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set for each model\n",
    "rf_predictions = rf_pipeline.predict(X_test)\n",
    "dt_predictions = dt_pipeline.predict(X_test)\n",
    "svm_predictions = svm_pipeline.predict(X_test)\n",
    "nb_predictions = nb_pipeline.predict(X_test)\n",
    "ann_predictions = ann_pipeline.predict(X_test)\n",
    "gb_predictions = gb_pipeline.predict(X_test)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "ensemble_predictions = (rf_predictions + dt_predictions + svm_predictions + nb_predictions + ann_predictions + gb_predictions) >= 3\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(f'Ensemble Model Accuracy: {ensemble_accuracy * 100:.2f}%')\n",
    "\n",
    "# Additional metrics for the ensemble model\n",
    "mse_ensemble = mean_squared_error(y_test, ensemble_predictions)\n",
    "mae_ensemble = mean_absolute_error(y_test, ensemble_predictions)\n",
    "recall_ensemble = recall_score(y_test, ensemble_predictions)\n",
    "conf_matrix_ensemble = confusion_matrix(y_test, ensemble_predictions)\n",
    "classification_rep_ensemble = classification_report(y_test, ensemble_predictions)\n",
    "\n",
    "# Print additional metrics for the ensemble model\n",
    "print(f'Mean Squared Error (MSE) for Ensemble Model: {mse_ensemble:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) for Ensemble Model: {mae_ensemble:.4f}')\n",
    "print(f'Recall for Ensemble Model: {recall_ensemble:.4f}')\n",
    "print(f'Confusion Matrix for Ensemble Model:\\n{conf_matrix_ensemble}')\n",
    "print(f'Classification Report for Ensemble Model:\\n{classification_rep_ensemble}')\n",
    "\n",
    "# Assuming 'pipeline' is a defined variable; replace with the actual pipeline variable you want to save if different\n",
    "joblib.dump(gb_pipeline, 'ensemble_model_predictions.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac80495170003c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T08:48:07.224686Z",
     "start_time": "2024-01-12T08:48:07.084990Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
